{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Tutorial 1\n",
    "\n",
    "The aim of this tutorial is to illustrate the structure and training method for Generative Adversarial Networks (GANs), highlighting the key ideas behind GANs and elucidating the topic with a working example, using Tensorflow and Keras to train a GAN on the MNIST dataset. Familiarity with the Keras functional API as well as general knowledge of deep learning will be useful.\n",
    "\n",
    "A GAN comprises of two separate neural networks, a Generator and a Discriminator. The objective of the generator is to produce objects that look as though they belong to any given dataset from random input. For example, we will consider the MNIST dataset in this tutorial. This dataset comprises of 28 x 28 arrays (that makes it a 784-dimensional dataset), and each array represents an image of a handwritten digit, 0-9. Each class of digit can be thought of as a manifold in 784-dimensional space, with an array lying on each manifold if and only if it is recognisable to a human as the corresponding digit. A good generator must therefore be good at mapping random inputs onto these manifolds, so that it will only generate images that look as if they belong to the true dataset.\n",
    "\n",
    "The second network, the Discriminator, has the opposite objective. It must learn to _discriminate_ between real examples from the dataset and the 'fakes' created by the Generator. The combined structure is as follows:\n",
    "\n",
    "![GAN_diagram.png](imgs_for_notebooks/GAN_diagram.png)\n",
    "\n",
    "The 'Adversarial' part of the name derives from the method of training GANs. They compete (as adversaries), each trying to beat the other, and we will see how this can be achieved with Keras momentarily. It is interesting to note that the generator will never see any real data - it will simply learn how to fool the discriminator by using the gradients propagated through the discriminator via the backpropagation algorithm. For this reason GANs are particularly susceptible to the vanishing gradients problem. After all, if the gradients vanish before reaching the generator there is no way for it to learn! This is particularly important to consider when using very deep GANs, but it should not be a worry for us here.\n",
    "\n",
    "Another common issue is that of 'Mode Collapse'. The generator can simply learn to generate the exact same thing regardless of the input. If this output is convincing, then the generator has completed its task despite being totally useless to us. \n",
    "\n",
    "We will consider overcoming these issues as they come up through this series of tutorials, but first we shall consider a very simple model in order to focus on understanding the training algorithm. Without further ado, let's get stuck in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules and functions\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Reshape, Flatten \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting the variables for the rest of the tutorial, if you wish to explore how different hyper-parameters affect the training, this is the place. It is particularly interesting to see how sensitive GANs are to the learning rates used, we can use different learning rates for the generator and discriminator, so tuning becomes more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting global random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# MNIST is black and white, so 1 channel\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "# Layout for displaying generated images \n",
    "PREVIEW_ROWS = 2\n",
    "PREVIEW_COLS = 5\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "# Optimisers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4,0.5)\n",
    "\n",
    "# Filepath for saving images\n",
    "PATH = 'C://Users/ewand/Jupyter Projects/GAN/Output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the MNIST dataset provided by the tensorflow_datasets module. The data is loaded, the pixel values scaled to range between -1 and 1, the range of the tanh activation function which will be used in the last layer of the generator. The data is then shuffled and batched according to the BATCH_SIZE and BUFFER_SIZE parameters. We use a buffer size of 60,000 (length of the dataset) so that the data is fully shuffled, and a Batch size of 128. Batch size can be tweaked, but be mindful of available RAM, if you get an Out of Memory Error, try reducing the batch size. The prefetch(1) call means that while one batch is being used to train the network, the next batch is being loaded into memory, which can help to prevent bottle-necking. This may not be a problem for MNIST as each image has relatively little data, but can make a difference for high resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(imgs):\n",
    "    return 2.*tf.cast(imgs, tf.float32)/255. - 1\n",
    "\n",
    "#Loading the data    \n",
    "(mnist_train, label_train), (mnist_test, label_test) = tfds.load('mnist',\n",
    "                                                                 split=['train', 'test'],\n",
    "                                                                 batch_size=-1,\n",
    "                                                                 as_supervised=True)\n",
    "# Scale\n",
    "mnist_train = scale_images(mnist_train)\n",
    "# Shuffle and batch\n",
    "mnist_train = tf.data.Dataset.from_tensor_slices(mnist_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplicity of MNIST allows us to get to grips with GANs with a simple dense structure. We will use a generator and discriminator with 3 dense hidden layers. Since we need to generate 28 x 28 images, the final layer will have 784 units, which can then be reshaped into the desired format. The other parameters can be played with. We will also use the standard tanh activation in the last layer, with the other layers having ReLu activation for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    # add an input layer\n",
    "    inputs = Input(shape=(SEED_SIZE,))\n",
    "    \n",
    "    # add the hidden layers\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(units=1024, activation='relu')(x)\n",
    "    \n",
    "    # add the output layer\n",
    "    x = Dense(units=28*28, activation='tanh')(x)\n",
    "    output = Reshape((28, 28, 1), input_shape=(28 * 28,))(x)\n",
    "    \n",
    "    # create the model\n",
    "    generator = Model(inputs=[inputs], outputs=[output], name='Generator')\n",
    "    return generator\n",
    "g=create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is the mirror image of the generator. This makes sense intuitively as it is trying to undo what the generator has done. It will predict 1 for 'Real', and 0 for 'Fake', so the sigmoid activation is used in the final layer. We use ReLu in the other layers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    # add input layer\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    x = Flatten()(inputs)\n",
    "\n",
    "    # add hidden layers\n",
    "    x = Dense(units=1024, activation='relu')(x)\n",
    "    x = Dense(units=512, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    \n",
    "    # add output layer\n",
    "    output = Dense(units=1, activation='sigmoid')(x)\n",
    "    \n",
    "    # create the model\n",
    "    discriminator = Model(inputs=[inputs], outputs=[output], name='Discriminator')\n",
    "    return discriminator\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these two networks can be combined into a GAN as if they are just layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GAN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "Generator (Model)            (None, 28, 28, 1)         1486352   \n",
      "_________________________________________________________________\n",
      "Discriminator (Model)        (None, 1)                 1460225   \n",
      "=================================================================\n",
      "Total params: 2,946,577\n",
      "Trainable params: 2,946,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output, name='GAN')\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to plot and save example generated images from each epoch of training\n",
    "\n",
    "def plot_generated_images(epoch, generator, noise, \n",
    "                          examples=PREVIEW_ROWS*PREVIEW_COLS, \n",
    "                          dim=(PREVIEW_ROWS, PREVIEW_COLS), \n",
    "                          figsize=(8,4)):\n",
    "    \n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples,28,28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')#, cmap='Greys')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PATH, f'dense_gan_generated_image {epoch}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs can't be trained using the model.fit() method that is used for simpler deep learning models in Keras. This is because we have two different networks that must be trained concurrently, but with opposite objectives. So we must create our own training loop to iterate over the batched data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=100):\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator= create_generator()\n",
    "    discriminator= create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    # Compiling models, 'trainable' only used when compiling, so doing it in this order means discriminator will train\n",
    "    # when discriminator.train_on_batch() is called, but not when gan.train_on_batch() is called.\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\n",
    "    discriminator.trainable = False\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=generator_optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    # Use fixed noise to generate example images.\n",
    "    example_noise = tf.random.normal(shape=(PREVIEW_ROWS*PREVIEW_COLS, 100), mean=0, stddev=1)\n",
    "    \n",
    "    # Produce plots of noise from before any training occurs.\n",
    "    plot_generated_images(0, generator, example_noise)\n",
    "    \n",
    "    for e in range(1,epochs+1): # Iterate through epochs.\n",
    "        print(f'Epoch {e}')\n",
    "        for batch in tqdm.notebook.tqdm(mnist_train): # Iterate through the batches, produces a nice progress bar.\n",
    "            \n",
    "            # Generate random noise as an input for the generator.\n",
    "            noise= tf.random.normal(shape=(BATCH_SIZE, 100), mean=0, stddev=1)\n",
    "            \n",
    "            # Generate fake images from noise.\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            # Construct different batches of  real and fake data.\n",
    "            X = tf.concat([batch, generated_images], axis=0)\n",
    "            \n",
    "            # Labels for generated and real data, discriminator should map real images to 1, fakes to 0.\n",
    "            # Soft labels are supposed to improve training.\n",
    "            y_dis_real = tf.random.uniform(shape = (BATCH_SIZE,), minval=0.9, maxval=1)\n",
    "            y_dis_fake = tf.random.uniform(shape = (BATCH_SIZE,), minval=0, maxval=0.1)\n",
    "            y_dis = tf.concat([y_dis_real, y_dis_fake], axis=0)\n",
    "            \n",
    "            # Train discriminator on batch first. Recall discriminator.trainable was True when discriminator was compiled,\n",
    "            # so the discriminator will train successfully with this call.\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            # Now we are going to train the generator to make the discriminator predict incorrectly, \n",
    "            # that is we want it to map the fakes to 1. We will use different random input since the previous noise was\n",
    "            # used to train the discriminator.\n",
    "            noise = tf.random.normal(shape = (BATCH_SIZE, 100), mean=0, stddev=1)\n",
    "            y_gen = tf.random.uniform(shape = (BATCH_SIZE,), minval=0.9, maxval=1)\n",
    "                        \n",
    "            # Then training the GAN with noise as input and targets as real makes the generator try to \n",
    "            # trick the discriminator. This process of adversarial training will continue until the generator \n",
    "            # produces good results. Recall that the discriminator weights are frozen in this step because of the \n",
    "            # order we compiled the models.\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "        # Plot generated images at every epoch. Using the same input noise to see how the images evolve.\n",
    "        plot_generated_images(e, generator, example_noise)\n",
    "    return generator, discriminator\n",
    "g, d = training(EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the following evolution through the epochs of training. Although we see different digits appearing throughout training, it seems to have mostly settled on drawing 1s which could be an example of mode collapse. This is where the generator learns to generate just one class from the dataset. If left to train longer, the discriminator would likely learn to classify that class as fake, at which point the generator would learn to generate another class, with this cycle continuing. Since we made no effort to prevent such behaviour, I believe we can count this result as a success, we clearly have a working training method for this class of neural network. \n",
    "![MNIST_gan4.gif](imgs_for_notebooks/MNIST_gan4.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
